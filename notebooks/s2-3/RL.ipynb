{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://webdocs.cs.ualberta.ca/~sutton/book/ebook/figtmp7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "- https://youtu.be/XiigTGKZfks - inverted pendulum\n",
    "- https://youtu.be/JpNAhKT7yY4\n",
    "- https://youtu.be/cyN-CRNrb3E\n",
    "- https://youtu.be/xM62SpKAZHU - flappy bird\n",
    "- https://youtu.be/qv6UVOQ0F44 - mario\n",
    "- https://youtu.be/0JL04JJjocc - helicopter\n",
    "- https://youtu.be/V1eYniJ0Rnk - atari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- State\n",
    "- Action\n",
    "- Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-armed Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Methods\n",
    "- $ \\epsilon $ - greedy\n",
    "- UCB  \n",
    "\n",
    "  \"Optimism in the Face of Uncertainty\"\n",
    "$$ a_t = argmax_{a \\in A} \\left\\{ \\hat{r}_a + CB_a\\right\\}$$\n",
    "UCB1: $$ a_t = argmax_{a \\in A} \\left\\{ \\hat{r}_a + \\sqrt{2\\log{\\frac{t}{n_a}}} \\right\\}$$\n",
    "- EXP3\n",
    "\n",
    "Auer, Peter, et al. \"Gambling in a rigged casino: The adversarial multi-armed bandit problem.\" Foundations of Computer Science, 1995. Proceedings., 36th Annual Symposium on. IEEE, 1995. \n",
    "- Thompson sampling\n",
    " $$p_a(r) = p(r|a)$$\n",
    " \n",
    " Chapelle, Olivier, and Lee Hong Li. An empirical evaluaTIon of Thompson sampling. Advances in Neural Information Processing Systems. 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: A/B testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Multi-armed Bandits\n",
    "$x$ - context\n",
    "$$ a_t(x) = argmax_{a \\in A} \\left\\{ \\hat{r}(x, w_a) + CB_a(x)\\right\\}$$\n",
    "\n",
    "$$ \\hat{r}(x, w_a) =  \\begin{cases}\n",
    "   x \\cdot w_a, \\> linear \\\\ \n",
    "   (1 + \\exp{(-x \\cdot w_a)})^{-1},  \\> logit \\\\ \n",
    "   \\Phi(x \\cdot w_a), \\>  probit\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Li,  Lihong, et al.\t\"A Contextual-Bandit Approach to Personalized News Article Recommendation\"  Proceedings of the 19th international conference on World wide web, ACM 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blackbox challange\n",
    "- http://blackboxchallenge.com/\n",
    "- https://habrahabr.ru/company/dca/blog/303286/\n",
    "- https://youtu.be/n9JKAQHGr80\n",
    "- https://github.com/amorgun/blackbox-2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://dataorigami.net/blogs/napkin-folding/79031811-multi-armed-bandits\n",
    "- https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PL5X3mDkKaJrL42i_jhE4N-p6E2Ol62Ofa\n",
    "- https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner\n",
    "- http://otoro.net/\n",
    "- https://github.com/aikorea/awesome-rl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
