{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn; seaborn.set()\n",
    "from ipywidgets import interact\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "scatter_args = dict(s=100, edgecolor='black', linewidth='1.5')\n",
    "autumn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def get_grid(data, step=0.01):\n",
    "    x_min, x_max = data.x.min() - 1, data.x.max() + 1\n",
    "    y_min, y_max = data.y.min() - 1, data.y.max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, step),\n",
    "                         np.arange(y_min, y_max, step))\n",
    "\n",
    "def get_score(X, y, cl):\n",
    "    return cross_val_score(cl, X, y, cv=5, scoring='mean_squared_error').mean()\n",
    "\n",
    "def show_classifier(X, y, cl,\n",
    "                    feature_modifier=lambda x: x,\n",
    "                    proba=True,\n",
    "                    print_score=False,\n",
    "                    grid=None):\n",
    "    if not grid:\n",
    "        xs, ys = get_grid(X)\n",
    "    else:\n",
    "        xs, ys = grid\n",
    "    xys = c_[ravel(xs), ravel(ys)]\n",
    "    cl.fit(feature_modifier(X), y)\n",
    "    if print_score:\n",
    "        print(\"MSE = {}\".format(get_score(feature_modifier(X), y, cl)))\n",
    "    if proba:\n",
    "        predicted = cl.predict_proba(feature_modifier(pd.DataFrame(xys, columns=('x', 'y'))))[:,1].reshape(xs.shape)\n",
    "    else:\n",
    "        predicted = cl.predict(feature_modifier(pd.DataFrame(xys, columns=('x', 'y')))).reshape(xs.shape)\n",
    "    pcolormesh(xs, ys, predicted)\n",
    "    scatter(X.x, X.y, c=y, alpha=0.5, **scatter_args)\n",
    "    autoscale(tight=True)\n",
    "    return cl\n",
    "\n",
    "np.random.seed(13)\n",
    "n = 100\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.vstack([\n",
    "        np.random.multivariate_normal((0,0), [[1, 0.3], [0.3, 0.7]], n),\n",
    "        random.multivariate_normal((1,2), [[1, -0.5], [-0.5, 1.6]], n)\n",
    "    ]), columns=['x', 'y'])\n",
    "df['target'] = np.hstack([np.ones(n), np.zeros(n)]).T\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "plt.scatter(df.x, df.y, c=df.target, **scatter_args);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "simple_tree = show_classifier(X, y, DecisionTreeClassifier(max_depth=3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%install_ext https://gist.githubusercontent.com/tempestadept/9322248/raw/8eb1fa343947d9628e71f10d47d1b3939a9df8a8/gvpng.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext gvpng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Перевод дерева в графвизовский формат dot\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "from sklearn import tree\n",
    "def vis_tree(cl, feature_names=['x', 'y']):\n",
    "    s = StringIO()\n",
    "    tree.export_graphviz(cl, out_file=s, feature_names=feature_names)\n",
    "    return s.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%dotstr vis_tree(simple_tree)\n",
    "show_classifier(X, y, DecisionTreeClassifier(max_depth=3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate: $$C(j,t) = \\frac{1}{n_{jt}} \\sum_{y_i: x_{ij} \\gt t} [y_i \\ne \\hat{y}]$$\n",
    "Gini: $$C(j,t) = \\sum_{k=1}^K p_i (1 - p_i) = 1 - \\sum_{k=1}^K p_i^2$$\n",
    "Entropy: $$H(p) = -\\sum_i p_i log_2(p_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = lambda p: -np.sum(p * np.log2(p)) if 0 not in p else 0\n",
    "gini = lambda p: 1. - (np.array(p)**2).sum()\n",
    "misclassification = lambda p: min(p)\n",
    "\n",
    "pvals = np.linspace(0, 1, num=51)        \n",
    "plt.plot(pvals, [entropy([p,1-p])/2. for p in pvals], label='Entropy')\n",
    "plt.plot(pvals, [gini([p,1-p]) for p in pvals], label='Gini')\n",
    "plt.plot(pvals, [misclassification([p,1-p]) for p in pvals], label='Misclassification rate')\n",
    "plt.legend()\n",
    "plt.title('Impurity functions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_size = 80\n",
    "np.random.seed(111)\n",
    "\n",
    "points_1d = pd.DataFrame(\n",
    "    {'x': np.hstack([\n",
    "            np.random.normal(loc=0, scale=1, size=(class_size // 2)),\n",
    "            np.random.normal(loc=4, scale=1, size=(class_size)),\n",
    "            np.random.normal(loc=7, scale=2, size=(class_size // 2))\n",
    "            ]),\n",
    "     'label':  np.hstack([\n",
    "            np.ones(class_size // 2),\n",
    "            np.zeros(class_size),\n",
    "            np.ones(class_size // 2)\n",
    "            ])\n",
    "})\n",
    "f, axarr = plt.subplots(4, sharex=True)\n",
    "\n",
    "axarr[0].set_title(\"Points\")\n",
    "axarr[0].scatter(points_1d.x, np.random.uniform(high=0.2, size=len(points_1d)), c=points_1d.label, s=40);\n",
    "steps = np.linspace(np.min(points_1d.x), np.max(points_1d.x), 100)\n",
    "def get_ratio_by_mask(arr, mask):\n",
    "    masked = arr[mask]\n",
    "    return np.sum(masked) / len(masked) if len(masked) else np.nan\n",
    "ratios = np.array([np.sum(points_1d.label[points_1d.x < k]) for k in steps])\n",
    "\n",
    "axarr[1].set_title(\"Ratio of class 1\")\n",
    "left_ratios = np.array([get_ratio_by_mask(points_1d.label, points_1d.x < k) for k in steps])\n",
    "right_ratios = np.array([get_ratio_by_mask(points_1d.label, points_1d.x >= k) for k in steps])\n",
    "axarr[1].plot(steps, left_ratios, label='Left part')\n",
    "axarr[1].plot(steps, right_ratios, '--', label='Right part')\n",
    "axarr[1].set_ylim([0, 1.1])\n",
    "axarr[1].legend(loc='best')\n",
    "\n",
    "axarr[2].set_title(\"Entropy\")\n",
    "vec_entropy = lambda p: -np.nan_to_num(p * np.log2(p) + (1 - p) * np.log2(1 - p))\n",
    "left_entropy = vec_entropy(left_ratios)\n",
    "axarr[2].plot(steps, left_entropy, label='Left part')\n",
    "right_entropy = vec_entropy(right_ratios)\n",
    "axarr[2].plot(steps, right_entropy, '--', label='Right part')\n",
    "axarr[2].set_ylim([-0.1, 1.1])\n",
    "axarr[2].legend(loc='best')\n",
    "\n",
    "axarr[3].set_title(\"Impurity\")\n",
    "weights = np.array([np.sum(points_1d.x < s) for s in steps]) / len(points_1d)\n",
    "impurity = weights * left_entropy + (1 - weights) * right_entropy\n",
    "axarr[3].set_ylim([0.6, 1.05])\n",
    "axarr[3].plot(steps, impurity, 'r', label='Right part')\n",
    "lowest_impurity = np.argmin(impurity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_classifier(X, y, DecisionTreeClassifier(), print_score=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_classifier(X, y, DecisionTreeClassifier(max_depth=3), print_score=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_features(X):\n",
    "    return pd.concat([X, pd.DataFrame({'f1': X.x + X.y, 'f2': X.x - X.y})], axis=1)\n",
    "\n",
    "show_classifier(X, y, DecisionTreeClassifier(max_depth=3),\n",
    "                feature_modifier=add_features,\n",
    "                print_score=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators_grid = [1, 10, 50]\n",
    "figure(figsize=(10, 8 * len(n_estimators_grid)))\n",
    "\n",
    "for index, n_estimators in enumerate(n_estimators_grid):\n",
    "    subplot(len(n_estimators_grid), 1, index + 1)\n",
    "    show_classifier(X, y, \n",
    "                    RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1));\n",
    "    title(\"n_estimators = {}\".format(n_estimators));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_data = pd.DataFrame(np.random.normal(size=(300, 2)), columns=['x', 'y'])\n",
    "r_data['target'] = (r_data.x ** 2 + r_data.y ** 2) ** 0.5\n",
    "r_features = r_data[['x', 'y']]\n",
    "r_data.plot(kind='scatter', x='x', y='y', c='target', colormap='autumn', colorbar=False, **scatter_args);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "show_classifier(r_features, r_data.target, \n",
    "                DecisionTreeRegressor(), proba=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs = []\n",
    "n_samples = 10\n",
    "figure(figsize=(10, 8*n_samples))\n",
    "sample_size = 100\n",
    "grid = get_grid(r_data, 0.1)\n",
    "\n",
    "for index in range(n_samples):\n",
    "    rows = r_data.ix[np.random.RandomState(index).choice(r_data.index, sample_size)]\n",
    "    subplot(n_samples, 1, index + 1)\n",
    "    clfs.append(show_classifier(rows[['x', 'y']], rows.target, \n",
    "                DecisionTreeRegressor(),\n",
    "                proba=False,\n",
    "                grid=grid));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs, ys = grid\n",
    "xys = c_[ravel(xs), ravel(ys)]\n",
    "predicted = [cl.predict(pd.DataFrame(xys, columns=('x', 'y'))).reshape(xs.shape) for cl in clfs]\n",
    "pcolormesh(xs, ys, np.mean(predicted, axis=0))\n",
    "scatter(r_data.x, r_data.y, c=r_data.target, **scatter_args)\n",
    "autoscale(tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "show_classifier(r_features, r_data.target, \n",
    "                RandomForestRegressor(n_estimators=10),\n",
    "                proba=False,\n",
    "                grid=grid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from itertools import chain, repeat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_plot_points(algorithm,\n",
    "                    n_estimators_grid,\n",
    "                    params,\n",
    "                    train_features, test_features,\n",
    "                    train_answers, test_answers):\n",
    "    train_errors, test_errors = [], []\n",
    "    for n_estimators in n_estimators_grid:\n",
    "        cl = algorithm(n_estimators=n_estimators, **params)\n",
    "        cl.fit(train_features, train_answers)\n",
    "        train_errors.append(mean_squared_error(cl.predict(train_features), train_answers))\n",
    "        test_errors.append(mean_squared_error(cl.predict(test_features), test_answers))\n",
    "    return train_errors, test_errors\n",
    "\n",
    "split = train_test_split(r_features, r_data.target, test_size=0.33, random_state=42)\n",
    "train_errors_rsm, test_errors_rsm = [], []\n",
    "n_estimators_grid = range(1, 361, 20)\n",
    "plot(*chain(*zip(repeat(n_estimators_grid),\n",
    "                 chain(get_plot_points(RandomForestRegressor, n_estimators_grid, {'n_jobs' : -1}, *split),\n",
    "                       get_plot_points(RandomForestRegressor, n_estimators_grid, {'n_jobs' : -1, 'max_features' : 1}, *split)\n",
    "                       ),\n",
    "                 ['r-', 'b-', 'r--', 'b--'])));\n",
    "legend(('Bagging (train)', 'Bagging (test)',\n",
    "        'Bagging + RSM (train)', 'Bagging + RSM (test)'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators_grid = [1, 10, 50]\n",
    "figure(figsize=(10, 8 * len(n_estimators_grid)))\n",
    "\n",
    "for index, n_estimators in enumerate(n_estimators_grid):\n",
    "    subplot(len(n_estimators_grid), 1, index + 1)\n",
    "    show_classifier(X, y, \n",
    "                    RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1),\n",
    "                    print_score=True);\n",
    "    title(\"n_estimators = {}\".format(n_estimators));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://scikit-learn.org/stable/modules/tree.html\n",
    "- https://github.com/tmadl/sklearn-expertsys\n",
    "- A Compact and Accurate Model for Classification, Mark Last, Oded Maimon\n",
    "- http://stackoverflow.com/questions/22722730/installing-pygraphviz-on-windows-python-2-7-graphviz-2-36"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
